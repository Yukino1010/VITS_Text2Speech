{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:41.794043Z","iopub.status.busy":"2024-08-02T06:20:41.793200Z","iopub.status.idle":"2024-08-02T06:20:47.364017Z","shell.execute_reply":"2024-08-02T06:20:47.363241Z","shell.execute_reply.started":"2024-08-02T06:20:41.794009Z"},"trusted":true},"outputs":[],"source":["import os\n","import math\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torchaudio\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.nn import Conv1d, ConvTranspose1d, AvgPool1d, Conv2d\n","\n","\n","from scipy.io.wavfile import read\n","from IPython.display import Audio\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.366370Z","iopub.status.busy":"2024-08-02T06:20:47.365946Z","iopub.status.idle":"2024-08-02T06:20:47.398334Z","shell.execute_reply":"2024-08-02T06:20:47.397490Z","shell.execute_reply.started":"2024-08-02T06:20:47.366344Z"},"trusted":true},"outputs":[],"source":["import sys\n","sys.path.append('/kaggle/input/vits-model')\n","import  monotonic_align, attentions\n","from common import slice_segments, sequence_mask, TextAudioCollate\n","from modules import WN, Flip, ResidualCouplingLayer, DurationPredictor\n","from mel_processing import mel_spectrogram_torch, spec_to_mel_torch, spectrogram_torch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.399771Z","iopub.status.busy":"2024-08-02T06:20:47.399442Z","iopub.status.idle":"2024-08-02T06:20:47.521703Z","shell.execute_reply":"2024-08-02T06:20:47.520707Z","shell.execute_reply.started":"2024-08-02T06:20:47.399740Z"},"trusted":true},"outputs":[],"source":["data_path = '/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1'\n","wavs_path = data_path + \"/wavs/\"\n","metadata_path = data_path + \"/metadata.csv\"\n","\n","# Read metadata file and parse it\n","metadata_df = pd.read_csv(metadata_path, sep=\"|\", header=None, quoting=3)\n","metadata_df.columns = [\"file_name\", \"transcription\", \"normalized_transcription\"]\n","metadata_df = metadata_df[[\"file_name\", \"normalized_transcription\"]]\n","metadata_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.523293Z","iopub.status.busy":"2024-08-02T06:20:47.522917Z","iopub.status.idle":"2024-08-02T06:20:47.532209Z","shell.execute_reply":"2024-08-02T06:20:47.531317Z","shell.execute_reply.started":"2024-08-02T06:20:47.523237Z"},"trusted":true},"outputs":[],"source":["# Text Encoding\n","_pad        = '_'\n","_punctuation = ';:,.!?¡¿—…\"«»“”ü ()-' + \"'\" + \"[]\" \n","_letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n","symbols = [_pad] + list(_punctuation) + list(_letters)\n","_symbol_to_id = {s: i for i, s in enumerate(symbols)}\n","_id_to_symbol = {i: s for i, s in enumerate(symbols)}\n","\n","def text_to_sequence(text):\n","    sequence = []\n","    for symbol in text:\n","        symbol_id = _symbol_to_id.get(symbol, None)\n","        if symbol_id is not None:\n","            sequence.append(symbol_id)\n","    return sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.535800Z","iopub.status.busy":"2024-08-02T06:20:47.535549Z","iopub.status.idle":"2024-08-02T06:20:47.555208Z","shell.execute_reply":"2024-08-02T06:20:47.554326Z","shell.execute_reply.started":"2024-08-02T06:20:47.535779Z"},"trusted":true},"outputs":[],"source":["class TextAudioLoader(torch.utils.data.Dataset):\n","    def __init__(self, audiopaths_and_text):\n","        self.audio_path = audiopaths_and_text['file_name'].values\n","        self.text = audiopaths_and_text['normalized_transcription'].values\n","        self.sampling_rate = 22050\n","\n","        self.max_wav_value = 32768.0\n","        self.filter_length = 1024\n","        self.hop_length = 256\n","        self.win_length = 1024\n","        self._filter()\n","        \n","    def _filter(self):\n","        audios = []\n","        texts = []\n","        \n","        for audiopath, text in zip(self.audio_path, self.text):\n","            if 1 <= len(text) and len(text) <= 100:\n","                audios.append(audiopath)\n","                texts.append(text) \n","        self.audio_path =  audios\n","        self.text = texts\n","        \n","    def get_audio(self, filename):\n","        full_path = '/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs/'+ filename + '.wav'\n","        sampling_rate, audio = read(full_path)\n","        audio = torch.FloatTensor(audio.astype(np.float32))\n","        \n","        if sampling_rate != self.sampling_rate:\n","            raise ValueError(\"{} {} SR doesn't match target {} SR\".format(\n","                sampling_rate, self.sampling_rate))\n","            \n","        audio_norm = audio / self.max_wav_value\n","        audio_norm = audio_norm.unsqueeze(0)\n","        spec = spectrogram_torch(audio_norm, self.filter_length,\n","            self.sampling_rate, self.hop_length, self.win_length,\n","            center=False)\n","        spec = torch.squeeze(spec, 0)\n","        return spec, audio_norm\n","            \n","    \n","    def get_text(self, text):\n","        text_norm = text_to_sequence(text)\n","        text_norm = torch.LongTensor(text_norm)\n","        return text_norm\n","\n","    def __getitem__(self, index):\n","        text = self.get_text(self.text[index])\n","        spec, audio_norm = self.get_audio(self.audio_path[index])\n","        return [text, spec, audio_norm]\n","    \n","    def play_audio(self, index):\n","        audio_path = self.audio_path[index]\n","        text = self.text[index]\n","        audio_path = '/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs/'+ audio_path + '.wav'\n","        audio, sr = torchaudio.load(audio_path)\n","        return Audio(audio.numpy(), rate=sr)\n","    \n","    def __len__(self):\n","        return len(self.audio_path)\n","    \n","\n","train_dataset = TextAudioLoader(metadata_df)\n","collate_fn = TextAudioCollate()\n","train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True,\\\n","                           pin_memory=True, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.556812Z","iopub.status.busy":"2024-08-02T06:20:47.556489Z","iopub.status.idle":"2024-08-02T06:20:47.567780Z","shell.execute_reply":"2024-08-02T06:20:47.567004Z","shell.execute_reply.started":"2024-08-02T06:20:47.556783Z"},"trusted":true},"outputs":[],"source":["class TextEncoder(nn.Module):\n","    def __init__(self,\n","        n_vocab,\n","        out_channels,\n","        hidden_channels,\n","        filter_channels,\n","        n_heads,\n","        n_layers,\n","        kernel_size,\n","        p_dropout):\n","        super().__init__()\n","        \n","        self.n_vocab = n_vocab\n","        self.out_channels = out_channels\n","        self.hidden_channels = hidden_channels\n","        self.filter_channels = filter_channels\n","        self.n_heads = n_heads\n","        self.n_layers = n_layers\n","        self.kernel_size = kernel_size\n","        self.p_dropout = p_dropout\n","        self.emb = nn.Embedding(n_vocab, hidden_channels)\n","\n","        self.encoder = attentions.Encoder(\n","            hidden_channels,\n","            filter_channels,\n","            n_heads,\n","            n_layers,\n","            kernel_size,\n","            p_dropout)             \n","        self.proj= Conv1d(hidden_channels, out_channels * 2, 1)\n","\n","    def forward(self, x, x_lengths):\n","        x = self.emb(x) * math.sqrt(self.hidden_channels) # [b, t, h]\n","        x = torch.transpose(x, 1, -1) # [b, h, t]\n","        x_mask = torch.unsqueeze(sequence_mask(x_lengths, x.size(2)), 1).to(x.dtype)\n","        x = self.encoder(x * x_mask, x_mask)\n","        \n","        stats = self.proj(x) * x_mask\n","        m, logs = torch.split(stats, self.out_channels, dim=1)\n","        return x, m, logs, x_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.569020Z","iopub.status.busy":"2024-08-02T06:20:47.568780Z","iopub.status.idle":"2024-08-02T06:20:47.578625Z","shell.execute_reply":"2024-08-02T06:20:47.577855Z","shell.execute_reply.started":"2024-08-02T06:20:47.568999Z"},"trusted":true},"outputs":[],"source":["class PosteriorEncoder(nn.Module):\n","    def __init__(self,\n","        in_channels,\n","        out_channels,\n","        hidden_channels,\n","        kernel_size = 5,\n","        dilation_rate = 1,\n","        n_layers = 16,\n","        gin_channels=0):\n","        \n","        super().__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.hidden_channels = hidden_channels\n","        self.kernel_size = kernel_size\n","        self.dilation_rate = dilation_rate\n","        self.n_layers = n_layers\n","        self.gin_channels = gin_channels\n","\n","        self.pre = Conv1d(in_channels, hidden_channels, 1)\n","        self.proj = Conv1d(hidden_channels, out_channels * 2, 1)\n","        self.enc = WN(hidden_channels, kernel_size, dilation_rate, n_layers, gin_channels=gin_channels)\n","\n","    def forward(self, x, x_lengths, g=None):\n","        x_mask = torch.unsqueeze(sequence_mask(x_lengths, x.size(2)), 1).to(x.dtype)\n","        x = self.pre(x) * x_mask \n","        x = self.enc(x, x_mask, g=g) # [b, h, spec_size]\n","        stats = self.proj(x) * x_mask # [b, h * 2, spec_size]\n","        m, logs = torch.split(stats, self.out_channels, dim=1)\n","        \n","        # z sampling (reparameterization trick)\n","        z = (m + torch.randn_like(m) * torch.exp(logs)) * x_mask\n","        return z, m, logs, x_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.579760Z","iopub.status.busy":"2024-08-02T06:20:47.579510Z","iopub.status.idle":"2024-08-02T06:20:47.591783Z","shell.execute_reply":"2024-08-02T06:20:47.590862Z","shell.execute_reply.started":"2024-08-02T06:20:47.579738Z"},"trusted":true},"outputs":[],"source":["def get_padding(kernel_size, dilation):\n","    return (kernel_size - 1) * dilation // 2\n","\n","def init_weights(m):\n","    if isinstance(m, nn.Conv1d):\n","        nn.init.kaiming_normal_(m.weight, nonlinearity='leaky_relu')\n","\n","class ResBlock(nn.Module):\n","    def __init__(self, channels, kernel_size=3, dilation=(1, 3, 5)):\n","        super(ResBlock, self).__init__()\n","        self.convs1 = nn.ModuleList([\n","            Conv1d(channels, channels, kernel_size, dilation=dilation[0],\n","                    padding=get_padding(kernel_size, dilation[0])),\n","            Conv1d(channels, channels, kernel_size, dilation=dilation[1],\n","                    padding=get_padding(kernel_size, dilation[1])),\n","            Conv1d(channels, channels, kernel_size, dilation=dilation[2],\n","                    padding=get_padding(kernel_size, dilation[2]))\n","        ])\n","        self.convs1.apply(init_weights)\n","        self.convs2 = nn.ModuleList([\n","            Conv1d(channels, channels, kernel_size, dilation=1,\n","                    padding=get_padding(kernel_size, 1)),\n","            Conv1d(channels, channels, kernel_size, dilation=1,\n","                    padding=get_padding(kernel_size, 1)),\n","            Conv1d(channels, channels, kernel_size, dilation=1,\n","                    padding=get_padding(kernel_size, 1))\n","        ])\n","        self.convs2.apply(init_weights)\n","\n","    def forward(self, x, x_mask=None):\n","        for c1, c2 in zip(self.convs1, self.convs2):\n","            xt = F.leaky_relu(x, 0.2)\n","            if x_mask is not None:\n","                xt = xt * x_mask\n","            xt = c1(xt)\n","            xt = F.leaky_relu(xt, 0.2)\n","            if x_mask is not None:\n","                xt = xt * x_mask\n","            xt = c2(xt)\n","            x = xt + x\n","        if x_mask is not None:\n","            x = x * x_mask\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.593099Z","iopub.status.busy":"2024-08-02T06:20:47.592869Z","iopub.status.idle":"2024-08-02T06:20:47.606408Z","shell.execute_reply":"2024-08-02T06:20:47.605614Z","shell.execute_reply.started":"2024-08-02T06:20:47.593080Z"},"trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, initial_channel, resblock_kernel_sizes, upsample_rates, \n","                 upsample_initial_channel, upsample_kernel_sizes, gin_channels=0):\n","        super(Decoder, self).__init__()\n","        self.num_kernels = len(resblock_kernel_sizes)\n","        self.num_upsamples = len(upsample_rates)\n","        self.conv_pre = Conv1d(initial_channel, upsample_initial_channel, 7, 1, padding=3)\n","\n","        self.ups = nn.ModuleList()\n","        for i, (u, k) in enumerate(zip(upsample_rates, upsample_kernel_sizes)):\n","            self.ups.append(ConvTranspose1d(upsample_initial_channel // (2 ** i), \\\n","                                            upsample_initial_channel // (2 ** (i + 1)), \\\n","                                            k, u, padding=(k - u) // 2))\n","\n","        self.resblocks = nn.ModuleList()\n","        for i in range(len(self.ups)):\n","            ch = upsample_initial_channel // (2 ** (i + 1))\n","            for k in resblock_kernel_sizes:\n","                self.resblocks.append(ResBlock(ch, k, [1, 3, 5]))\n","\n","        self.conv_post = Conv1d(ch, 1, 7, 1, padding=3, bias=False)\n","        if gin_channels != 0:\n","            self.cond = Conv1d(gin_channels, upsample_initial_channel, 1)\n","\n","    def forward(self, x, g=None):\n","        x = self.conv_pre(x)\n","        if g is not None:\n","            x = x + self.cond(g)\n","\n","        for i in range(self.num_upsamples):\n","            x = F.leaky_relu(x, 0.2)\n","            x = self.ups[i](x)\n","            xs = None\n","            for j in range(self.num_kernels):\n","                if xs is None:\n","                    xs = self.resblocks[i * self.num_kernels + j](x)\n","                else:\n","                    xs += self.resblocks[i * self.num_kernels + j](x)\n","            x = xs / self.num_kernels\n","        x = F.leaky_relu(x)\n","        x = self.conv_post(x)\n","        x = torch.tanh(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.607761Z","iopub.status.busy":"2024-08-02T06:20:47.607481Z","iopub.status.idle":"2024-08-02T06:20:47.616924Z","shell.execute_reply":"2024-08-02T06:20:47.616159Z","shell.execute_reply.started":"2024-08-02T06:20:47.607739Z"},"trusted":true},"outputs":[],"source":["class ResidualCouplingBlock(nn.Module):\n","    def __init__(self,\n","        channels,\n","        hidden_channels,\n","        kernel_size = 5,\n","        dilation_rate = 1,\n","        n_layers = 4,\n","        n_flows=4,\n","        gin_channels=0):\n","        super().__init__()\n","        self.channels = channels\n","        self.hidden_channels = hidden_channels\n","        self.kernel_size = kernel_size\n","        self.dilation_rate = dilation_rate\n","        self.n_layers = n_layers\n","        self.n_flows = n_flows\n","        self.gin_channels = gin_channels\n","\n","        self.flows = nn.ModuleList()\n","        for i in range(n_flows):\n","            self.flows.append(ResidualCouplingLayer(channels, hidden_channels, kernel_size, \\\n","                                                    dilation_rate, n_layers, gin_channels=gin_channels))\n","            self.flows.append(Flip())\n","\n","    def forward(self, x, x_mask, g=None, reverse=False):\n","        if not reverse:\n","            for flow in self.flows:\n","                x, logdet = flow(x, x_mask, g=g, reverse=reverse)\n","        else:\n","            for flow in reversed(self.flows):\n","                x = flow(x, x_mask, g=g, reverse=reverse)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.618501Z","iopub.status.busy":"2024-08-02T06:20:47.618197Z","iopub.status.idle":"2024-08-02T06:20:47.638811Z","shell.execute_reply":"2024-08-02T06:20:47.638042Z","shell.execute_reply.started":"2024-08-02T06:20:47.618479Z"},"trusted":true},"outputs":[],"source":["class VITGenerator(nn.Module):\n","    def __init__(self, n_vocab, inter_channels, hidden_channels, filter_channels, spec_channels):\n","        super().__init__()\n","        self.enc_p = TextEncoder(n_vocab,\n","            inter_channels,\n","            hidden_channels,\n","            filter_channels,\n","            n_heads = 2,\n","            n_layers = 6,\n","            kernel_size = 3,\n","            p_dropout = 0.1)\n","        \n","        self.seg_size = 8192 // 256\n","        self.dec = Decoder(inter_channels, [3,7,11], [8,8,2,2], 512, [16,16,4,4])\n","        self.enc_q = PosteriorEncoder(spec_channels, inter_channels, hidden_channels)\n","        self.flow = ResidualCouplingBlock(inter_channels, hidden_channels)\n","        self.dp = DurationPredictor(hidden_channels)\n","    \n","    def forward(self, x, x_lengths, y, y_lengths):\n","        g = None\n","        x, m_p, logs_p, x_mask = self.enc_p(x, x_lengths)\n","        z, m_q, logs_q, y_mask = self.enc_q(y, y_lengths, g=g)\n","        z_p = self.flow(z, y_mask, g=g)\n","        \n","        with torch.no_grad():\n","            # negative cross-entropy\n","            s_p_sq_r = torch.exp(-2 * logs_p) # [b, d, t]\n","            neg_cent1 = torch.sum(-0.5 * math.log(2 * math.pi) - logs_p, [1], keepdim=True)\n","            neg_cent2 = torch.matmul(-0.5 * (z_p ** 2).transpose(1, 2), s_p_sq_r) \n","            neg_cent3 = torch.matmul(z_p.transpose(1, 2), (m_p * s_p_sq_r))\n","            neg_cent4 = torch.sum(-0.5 * (m_p ** 2) * s_p_sq_r, [1], keepdim=True) \n","            neg_cent = neg_cent1 + neg_cent2 + neg_cent3 + neg_cent4\n","            \n","            attn_mask = torch.unsqueeze(x_mask, 2) * torch.unsqueeze(y_mask, -1)\n","            attn = monotonic_align.maximum_path(neg_cent, attn_mask.squeeze(1)).unsqueeze(1).detach()\n","\n","        w = attn.sum(2)\n","        logw_ = torch.log(w + 1e-6) * x_mask\n","        logw = self.dp(x, x_mask, g=g)\n","        l_length = torch.sum((logw - logw_)**2, [1,2]) / torch.sum(x_mask) # for averaging \n","        \n","        # expand prior\n","        m_p = torch.matmul(attn.squeeze(1), m_p.transpose(1, 2)).transpose(1, 2)\n","        logs_p = torch.matmul(attn.squeeze(1), logs_p.transpose(1, 2)).transpose(1, 2)\n","        z_slice, ids_slice = slice_segments(z, x_lengths = y_lengths, segment_size = self.seg_size)\n","        o = self.dec(z_slice, g=g)\n","        return o, l_length, attn, ids_slice, x_mask, y_mask, (z, z_p, m_p, logs_p, m_q, logs_q)\n","    \n","    def infer(self, x, x_lengths, max_len=None):\n","        g = None\n","        x, m_p, logs_p, x_mask = self.enc_p(x, x_lengths)\n","        logw = self.dp(x, x_mask, g=g)\n","        \n","        w = torch.exp(logw) * x_mask \n","        w_ceil = torch.ceil(w)\n","        y_lengths = torch.clamp_min(torch.sum(w_ceil, [1, 2]), 1).long()\n","        y_mask = torch.unsqueeze(sequence_mask(y_lengths, None), 1).to(x_mask.dtype)\n","        attn_mask = torch.unsqueeze(x_mask, 2) * torch.unsqueeze(y_mask, -1)\n","        attn = monotonic_align.generate_path(w_ceil, attn_mask)\n","        m_p = torch.matmul(attn.squeeze(1), m_p.transpose(1, 2)).transpose(1, 2)\n","        logs_p = torch.matmul(attn.squeeze(1), logs_p.transpose(1, 2)).transpose(1, 2)\n","\n","        z_p = m_p + torch.randn_like(m_p) * torch.exp(logs_p)\n","        z = self.flow(z_p, y_mask, g=g, reverse=True)\n","        o = self.dec((z * y_mask)[:,:,:max_len], g=g)\n","        return o, attn, y_mask, (z, z_p, m_p, logs_p)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.640210Z","iopub.status.busy":"2024-08-02T06:20:47.639890Z","iopub.status.idle":"2024-08-02T06:20:47.654672Z","shell.execute_reply":"2024-08-02T06:20:47.653898Z","shell.execute_reply.started":"2024-08-02T06:20:47.640177Z"},"trusted":true},"outputs":[],"source":["class HiFiGANDiscriminator(nn.Module):\n","    def __init__(self, period):\n","        super(HiFiGANDiscriminator, self).__init__()\n","        self.period = period\n","        self.convs = nn.ModuleList([\n","            nn.Conv2d(1, 32, (5, 1), (3, 1), padding=(2, 0)),\n","            nn.Conv2d(32, 128, (5, 1), (3, 1), padding=(2, 0)),\n","            nn.Conv2d(128, 512, (5, 1), (3, 1), padding=(2, 0)),\n","            nn.Conv2d(512, 1024, (5, 1), (3, 1), padding=(2, 0)),\n","            nn.Conv2d(1024, 1024, (5, 1), 1, padding=(2, 0))\n","        ])\n","        self.conv_post = nn.Conv2d(1024, 1, (3, 1), 1, padding=(1, 0))\n","        self.leaky_relu = nn.LeakyReLU(0.1)\n","\n","    def forward(self, x):\n","        fmap = []\n","        b, c, t = x.shape\n","        if t % self.period != 0:\n","            n_pad = self.period - (t % self.period)\n","            x = F.pad(x, (0, n_pad), 'reflect')\n","            t = t + n_pad\n"," \n","        x = x.view(b, c, t // self.period, self.period)\n","        for l in self.convs:\n","            x = self.leaky_relu(l(x))\n","            fmap.append(x)\n","        x = self.conv_post(x)\n","        fmap.append(x)\n","        x = torch.flatten(x, 1, -1)\n","        return x, fmap\n","\n","class MultiScaleDiscriminator(nn.Module):\n","    def __init__(self):\n","        super(MultiScaleDiscriminator, self).__init__()\n","        self.discriminators = nn.ModuleList([\n","            HiFiGANDiscriminator(2),\n","            HiFiGANDiscriminator(3),\n","            HiFiGANDiscriminator(5)\n","        ])\n","\n","    def forward(self, y, y_hat):\n","        y_d_rs = []\n","        y_d_gs = []\n","        fmap_rs = []\n","        fmap_gs = []\n","        \n","        for d in self.discriminators:\n","            y_d_r, fmap_r = d(y)\n","            y_d_g, fmap_g = d(y_hat)\n","            y_d_rs.append(y_d_r)\n","            y_d_gs.append(y_d_g)\n","            fmap_rs.append(fmap_r)\n","            fmap_gs.append(fmap_g)\n","        return y_d_rs, y_d_gs, fmap_rs, fmap_gs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.656666Z","iopub.status.busy":"2024-08-02T06:20:47.655848Z","iopub.status.idle":"2024-08-02T06:20:47.668167Z","shell.execute_reply":"2024-08-02T06:20:47.667311Z","shell.execute_reply.started":"2024-08-02T06:20:47.656632Z"},"trusted":true},"outputs":[],"source":["def feature_loss(fmap_r, fmap_g):\n","    # Computes the Mean Absolute Error (MAE) \\\n","    # between the feature maps of real and generated data.\n","    \n","    loss = 0\n","    for dr, dg in zip(fmap_r, fmap_g):\n","        for rl, gl in zip(dr, dg):\n","            rl = rl.float().detach()\n","            gl = gl.float()\n","            loss += torch.mean(torch.abs(rl - gl))\n","    return loss * 2 \n","\n","def discriminator_loss(disc_real_outputs, disc_generated_outputs):\n","    loss = 0\n","    r_losses = []\n","    g_losses = []\n","    for dr, dg in zip(disc_real_outputs, disc_generated_outputs):\n","        dr = dr.float()\n","        dg = dg.float()\n","        r_loss = torch.mean((1-dr)**2)\n","        g_loss = torch.mean(dg**2)\n","        loss += (r_loss + g_loss)\n","        r_losses.append(r_loss.item())\n","        g_losses.append(g_loss.item())\n","\n","    return loss, r_losses, g_losses\n","\n","def generator_loss(disc_outputs):\n","    loss = 0\n","    gen_losses = []\n","    for dg in disc_outputs:\n","        dg = dg.float()\n","        l = torch.mean((1-dg)**2)\n","        gen_losses.append(l)\n","        loss += l\n","        \n","    return loss, gen_losses\n","\n","def kl_loss(z_p, logs_q, m_p, logs_p, z_mask):\n","    z_p = z_p.float()\n","    logs_q = logs_q.float()\n","    m_p = m_p.float()\n","    logs_p = logs_p.float()\n","    z_mask = z_mask.float()\n","\n","    kl = logs_p - logs_q - 0.5\n","    kl += 0.5 * ((z_p - m_p)**2) * torch.exp(-2. * logs_p)\n","    kl = torch.sum(kl * z_mask)\n","    l = kl / torch.sum(z_mask)\n","    return l"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.671849Z","iopub.status.busy":"2024-08-02T06:20:47.671590Z","iopub.status.idle":"2024-08-02T06:20:47.678216Z","shell.execute_reply":"2024-08-02T06:20:47.677322Z","shell.execute_reply.started":"2024-08-02T06:20:47.671823Z"},"trusted":true},"outputs":[],"source":["import time\n","import soundfile as sf\n","from tqdm import *\n","from torch.cuda.amp import autocast, GradScaler\n","\n","def save_audio(y_hat, epochs, sample_rate=22050):\n","    if not isinstance(y_hat, np.ndarray):\n","        y_hat = y_hat.detach().cpu().numpy()\n","\n","    for i in range(y_hat.shape[0]):\n","        audio_segment = y_hat[i, 0, :] \n","        file_name = f\"audio_segment_{epochs}_{i+1}.wav\"\n","        sf.write(file_name, audio_segment, sample_rate)\n","        print(f\"Saved {file_name}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.679966Z","iopub.status.busy":"2024-08-02T06:20:47.679648Z","iopub.status.idle":"2024-08-02T06:20:47.706254Z","shell.execute_reply":"2024-08-02T06:20:47.705437Z","shell.execute_reply.started":"2024-08-02T06:20:47.679937Z"},"trusted":true},"outputs":[],"source":["class VitTrainer():\n","    def __init__(self, g, d, data_loader, total_steps, save_n_steps, \\\n","                 ckpt_dir, LR, device='cuda', load_path = None):\n","        super().__init__()\n","        self.g = g.to(device)\n","        self.d = d.to(device)\n","        \n","        self.data_loader = data_loader\n","        self.optim_g = torch.optim.AdamW(self.g.parameters(), LR, betas=[0.8, 0.99], eps=1e-9)                 \n","        self.optim_d = torch.optim.AdamW(self.d.parameters(), LR, betas=[0.8, 0.99], eps=1e-9)\n","        self.scaler = GradScaler(enabled=True)\n","        \n","        self.step = 1\n","        self.ckpt_dir = ckpt_dir\n","        self.device = device\n","        self.total_steps = total_steps\n","        self.save_n_steps = save_n_steps\n","        \n","        if load_path is not None:\n","            self.load_state_dict(load_path)\n","            print(\"sucessful load state dict !!!!!!\")\n","            print(f\"start from step {self.step}\")\n","        \n","    def state_dict(self, step):\n","        return {\n","            \"step\": step,\n","            'g': self.g.state_dict(),\n","            'd': self.d.state_dict()\n","        }\n","    \n","    def load_state_dict(self, path):\n","        state_dict = torch.load(path)\n","        self.g.load_state_dict(state_dict['g'])\n","        self.d.load_state_dict(state_dict['d'])\n","        self.step = state_dict['step']\n","        \n","    def train(self):\n","        start = time.time()\n","        print(f'Start of step {self.step}')\n","    \n","        for step in tqdm(range(self.step, self.total_steps+1), desc=f\"Training progress\"):\n","            x, x_lengths, spec, spec_lengths, y, y_lengths = next(iter(self.data_loader))\n","            x, x_lengths = x.to(self.device), x_lengths.to(self.device)\n","            spec, spec_lengths = spec.to(self.device), spec_lengths.to(self.device)\n","            y, y_lengths = y.to(self.device), y_lengths.to(self.device)\n","\n","            with autocast(enabled=True):\n","                y_hat, l_length, attn, ids_slice, x_mask, z_mask,\\\n","                (z, z_p, m_p, logs_p, m_q, logs_q) = self.g(x, x_lengths, spec, spec_lengths)\n","                mel = spec_to_mel_torch(spec, 1024, 80, 22050, 0.0, None)\n","                y_mel, _ = slice_segments(mel, ids_str = ids_slice, segment_size = 8192 // 256)\n","                y_hat_mel = mel_spectrogram_torch(y_hat.squeeze(1), 1024, 80, 22050, 256, 1024, 0.0, None)\n","                y, _ = slice_segments(y, ids_str = ids_slice * 256, segment_size = 8192) \n","\n","                # Discriminator\n","                y_d_hat_r, y_d_hat_g, _, _ = self.d(y, y_hat.detach())\n","                with autocast(enabled=False):\n","                    loss_disc, losses_disc_r, losses_disc_g = discriminator_loss(y_d_hat_r, y_d_hat_g)\n","                    loss_disc_all = loss_disc\n","        \n","            self.optim_d.zero_grad()\n","            self.scaler.scale(loss_disc_all).backward()\n","            self.scaler.unscale_(self.optim_d)\n","            self.grad_norm = nn.utils.clip_grad_norm_(self.d.parameters(), 1e9)\n","            self.scaler.step(self.optim_d)\n","\n","            with autocast(enabled=True):\n","                y_d_hat_r, y_d_hat_g, fmap_r, fmap_g = self.d(y, y_hat)\n","                with autocast(enabled=False):\n","                    loss_dur = torch.sum(l_length.float())\n","                    loss_mel = F.l1_loss(y_mel, y_hat_mel) * 45\n","                    loss_kl = kl_loss(z_p, logs_q, m_p, logs_p, z_mask)\n","\n","                    loss_fm = feature_loss(fmap_r, fmap_g)\n","                    loss_gen, losses_gen = generator_loss(y_d_hat_g)\n","                    loss_gen_all = loss_gen + loss_fm + loss_mel + loss_dur + loss_kl\n","                    \n","            self.optim_g.zero_grad()\n","            self.scaler.scale(loss_gen_all).backward()\n","            self.scaler.unscale_(self.optim_g)\n","            self.grad_norm = nn.utils.clip_grad_norm_(self.g.parameters(), 1e9)\n","            self.scaler.step(self.optim_g)\n","            self.scaler.update()\n","            \n","            if step % self.save_n_steps == 0:\n","                epoch = step // self.save_n_steps\n","                time_minutes = (time.time() - start) / 60\n","                torch.save(self.state_dict(step), f\"{self.ckpt_dir}/weight_tts_epoch{epoch}.pt\")\n","                \n","                print(f\"epoch: {epoch}, d_loss: {loss_disc_all.data} ~~~~~~\")\n","                print(f\"epoch: {epoch}, g_loss: {loss_gen_all.data} ~~~~~~\")\n","                print (f'Time taken for epoch {epoch} is {time_minutes:.3f} min\\n') \n","                print(f\"sucessful saving epoch {epoch} state dict !!!!!!!\")\n","                start = time.time()\n","                self.generate(epoch)\n","              \n","    def get_input(self, text):\n","        text = text_to_sequence(text)\n","        text_len = torch.tensor(len(text)).to(self.device).unsqueeze(0)\n","        text = torch.LongTensor(text).to(self.device).unsqueeze(0)\n","        return text, text_len\n","\n","    def generate(self, epochs, text=None):\n","        self.g.eval()\n","        x, x_lengths, spec, spec_lengths, y, y_lengths = next(iter(self.data_loader))\n","        x, x_lengths = x.cuda(0), x_lengths.cuda(0)\n","        x = x[:4]\n","        x_lengths = x_lengths[:4]\n","        \n","        if text is not None:\n","            x, x_lengths = self.get_input(text)\n","\n","        y_hat, attn, mask, *_ = self.g.infer(x, x_lengths, max_len=1000)\n","        y_hat_lengths = mask.sum([1,2]).long() * 256\n","        save_audio(y_hat, epochs)\n","        self.g.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:47.707581Z","iopub.status.busy":"2024-08-02T06:20:47.707290Z","iopub.status.idle":"2024-08-02T06:20:49.992098Z","shell.execute_reply":"2024-08-02T06:20:49.991140Z","shell.execute_reply.started":"2024-08-02T06:20:47.707558Z"},"trusted":true},"outputs":[],"source":["n_vocab = len(symbols)\n","spec_channels = 1024 // 2 + 1\n","spec_size = 8192 // 256\n","hop_length = 256\n","\n","inter_channels = 192\n","hidden_channels = 192\n","filter_channels = 768\n","\n","total_iters = 15000\n","save_n_iters = 1500\n","LR = 2e-4\n","load_path = None\n","ckpt_dir = './model_weight/'\n","os.makedirs(ckpt_dir, exist_ok=True)\n","\n","d_model = MultiScaleDiscriminator()\n","g_model = VITGenerator(n_vocab, inter_channels, hidden_channels, filter_channels, spec_channels)       \n","trainer = VitTrainer(g_model, d_model, train_loader, total_iters,\\\n","                     save_n_iters, ckpt_dir, LR, load_path=load_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T06:20:49.993625Z","iopub.status.busy":"2024-08-02T06:20:49.993214Z"},"trusted":true},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["inp_text= None\n","trainer.generate(-1, inp_text)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1159053,"sourceId":1942970,"sourceType":"datasetVersion"},{"datasetId":5482918,"sourceId":9086995,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
